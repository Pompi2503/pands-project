{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a50d67",
   "metadata": {},
   "source": [
    "## Deepika Gusain\n",
    "## Module: Programming and Scripting\n",
    "## Project: Iris Data Analysis  \n",
    "This report is submitted as part of the final project requirement for the Programming and Scripting module. It involves a deep analysis and implementation of Fisher's Iris Dataset using Python, including research, code development, statistical analysis, visualisation, and thorough documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e7b29",
   "metadata": {},
   "source": [
    "### 1. Introduction \n",
    "This project has been designed to give practical exposure to the real-world use of scripting and data analysis. The Iris dataset is chosen as it is foundational in machine learning and statistics. The report outlines the detailed steps, challenges, and achievements from beginning to the end of the project. A strong focus has been placed on the modular programming, version control, research quality, and presentation clarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8563b",
   "metadata": {},
   "source": [
    "### 2. Research Investigations  \n",
    "Extensive research was conducted on the Iris dataset from multiple reliable sources, including the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/iris), academic literatures (https://doi.org/10.1111/j.1469-1809.1936.tb02137.x), and Python documentation for libraries such as Pandas (https://pandas.pydata.org/docs/), Seaborn (https://seaborn.pydata.org/), and Matplotlib (https://matplotlib.org/stable/contents.html).\n",
    "Ronald Fisher introduced this dataset in 1936 to demonstrate linear discriminant analysis. The dataset includes 150 samples of iris flowers from three species. Each sample records four measurements: sepal length, sepal width, petal length, and petal width.  \n",
    "In addition to data structure, background on the application of this dataset in classification problems and statistical modeling was investigated. Sources were cross-referenced to ensure accuracy, and all data references are fully cited. The research also covered visualization techniques and best practices in scientific reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f6020",
   "metadata": {},
   "source": [
    "### 3. Development and Implementation\n",
    "The project was implemented entirely in Python. The script `analysis.py` was developed to perform the following:\n",
    "- Load the Iris dataset using Seaborn\n",
    "- Save the dataset as `iris.csv`\n",
    "- Generate and save summary statistics to `variable_summary.txt`\n",
    "- Plot and save histograms for each numerical feature\n",
    "- Create and save scatter plots for all feature pairs\n",
    "\n",
    "The code was developed with clarity and maintainability in mind. Each block of logic is accompanied by comments. Functions were reused where applicable, and filenames were dynamically generated to reduce redundancy. The code was tested and refined iteratively, with each improvement committed to the version control system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcef01",
   "metadata": {},
   "source": [
    "### 4. Consistency and Version Control\n",
    "GitHub was used to track every aspect of the development process. The repository (`pands-project`) was structured with a meaningful commit history. Each commit was atomic, addressing only one change or feature at a time. This helped maintain clarity and supported collaborative best practices.\n",
    "\n",
    "The following structure was maintained:\n",
    "- Regular commits\n",
    "- Clear commit messages\n",
    "- Use of `.gitignore`\n",
    "- Inclusion of `README.md`, `requirements.txt`, and data/plots\n",
    "\n",
    "Issues and milestones were optionally used to keep track of progress. This consistent approach ensured a traceable project workflow and reflects a professional development attitude. commit was atomic, addressing only one change or feature at a time. This helped maintain clarity and supported collaborative best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b615af7",
   "metadata": {},
   "source": [
    "### 5. Documentation and Readability\n",
    "This report and the accompanying README file were written to high academic standards. Every section, from introduction to conclusion, is designed to be understandable even to a reader with a minimal technical background.\n",
    "\n",
    "The README includes:\n",
    "- Project purpose\n",
    "- Dataset background\n",
    "- Installation and execution instructions\n",
    "- Detailed analysis overview\n",
    "- Visualizations and insights\n",
    "- References\n",
    "\n",
    "The code is fully commented and formatted to improve readability. Variable names are descriptive, and plotting functions include titles, labels, and legends for clarity.  clarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106a2f7",
   "metadata": {},
   "source": [
    "### 6. Data Analysis Techniques\n",
    "Exploratory Data Analysis (EDA) techniques such as summary statistics, histograms, and scatter plots were used to gain insights into the Iris dataset. This provided a better understanding of distributions, relationships, and potential feature importance for classification tasks.\n",
    "\n",
    "In particular, petal length and petal width showed strong separation between the species. Scatter plots using hue for species made this trend visually clear. Histograms were used to verify normality and detect outliers in measurement distributions. Exploratory Data Analysis (EDA) techniques such as summary statistics, histograms, and scatter plots were used to gain insights into the Iris dataset. This provided a better understanding of distributions, relationships, and potential feature importance for classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9652579",
   "metadata": {},
   "source": [
    "### 7. Visualizations\n",
    "Seaborn and Matplotlib were used to generate plots. The visualizations created include:\n",
    "- Histogram of each feature (sepal/petal length and width)\n",
    "- Pairwise scatter plots (e.g., sepal length vs sepal width)\n",
    "\n",
    "All visuals were saved into a 'plots' directory and named consistently. The plots followed design best practices: readable labels, color coding by species, and appropriate use of figure sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17560cbb",
   "metadata": {},
   "source": [
    "### 8. Code Quality and Structure\n",
    "The code was structured into reusable, logical blocks. For example, functions were used to generate plots in loops. All outputs were dynamically saved using formatted strings.\n",
    "\n",
    "Code comments and modular structure ensure that anyone reading or using the code can follow and replicate the analysis with ease. The script follows Pythonic conventions and has been tested to run without errors. The code was structured into reusable, logical blocks. For example, functions were used to generate plots in loops. All outputs were dynamically saved using formatted strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497ed40",
   "metadata": {},
   "source": [
    "### 9. Learning Reflections\n",
    "This project significantly contributed to the development of scripting, version control, and analytical skills. Understanding how to structure a project, keep it organized, and present it to others was one of the most valuable takeaways.\n",
    "\n",
    "This experience highlighted the importance of research before implementation, testing throughout development, and writing user-friendly documentation. From using Git efficiently to visualizing real-world data, the skills learned here are applicable far beyond this assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b1f08",
   "metadata": {},
   "source": [
    "### 10. Conclusion\n",
    "The project met all objectives as defined in the brief. From loading the data, conducting EDA, creating visual outputs, and documenting the process, each part has been completed to a high standard with special focus on research, coding, and communication. This report, along with the GitHub repository, serves as proof of a structured and thorough approach to problem-solving using programming and scripting.  coding, and communication. This report, along with the GitHub repository, serves as proof of a structured and thorough approach to problem-solving using programming and scripting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34f6a6",
   "metadata": {},
   "source": [
    "### 11. References\n",
    "- Fisher, R.A. (1936). The use of multiple measurements in taxonomic problems.\n",
    "- UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/iris\n",
    "- Python: https://www.python.org/\n",
    "- Pandas: https://pandas.pydata.org/\n",
    "- Seaborn: https://seaborn.pydata.org/\n",
    "- Matplotlib: https://matplotlib.org/\n",
    "- GitHub Documentation: https://docs.github.com/- Fisher, R.A. (1936). The use of multiple measurements in taxonomic problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af371350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Outputs saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# Save to CSV (if needed)\n",
    "iris.to_csv('iris.csv', index=False)\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Summary stats\n",
    "summary = iris.describe()\n",
    "summary.to_csv('variable_summary.txt', sep='\\t')\n",
    "\n",
    "# Histograms\n",
    "for column in iris.columns[:-1]:\n",
    "    plt.figure()\n",
    "    sns.histplot(iris[column], kde=True, bins=20)\n",
    "    plt.title(f'Histogram of {column}')\n",
    "    plt.savefig(f'plots/histogram_{column}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Scatter plots for all pairs\n",
    "for x, y in itertools.combinations(iris.columns[:-1], 2):\n",
    "    plt.figure()\n",
    "    sns.scatterplot(data=iris, x=x, y=y, hue='species')\n",
    "    plt.title(f'Scatter Plot: {x} vs {y}')\n",
    "    plt.savefig(f'plots/scatter_{x}_vs_{y}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Analysis complete. Outputs saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
